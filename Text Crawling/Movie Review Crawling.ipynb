{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1页电影\n",
      "第1部电影的评论\n",
      "https://www.imdb.com/title/tt4943998/reviews?spoiler=hide&sort=helpfulnessScore&dir=desc&ratingFilter=0\n",
      "已爬取第1部电影的评论共229条\n",
      "第2部电影的评论\n",
      "https://www.imdb.com/title/tt8425058/reviews?spoiler=hide&sort=helpfulnessScore&dir=desc&ratingFilter=0\n",
      "已爬取第2部电影的评论共97条\n",
      "第3部电影的评论\n",
      "https://www.imdb.com/title/tt8022928/reviews?spoiler=hide&sort=helpfulnessScore&dir=desc&ratingFilter=0\n",
      "已爬取第3部电影的评论共66条\n",
      "第4部电影的评论\n",
      "https://www.imdb.com/title/tt10090796/reviews?spoiler=hide&sort=helpfulnessScore&dir=desc&ratingFilter=0\n",
      "已爬取第4部电影的评论共60条\n",
      "第5部电影的评论\n",
      "https://www.imdb.com/title/tt12885438/reviews?spoiler=hide&sort=helpfulnessScore&dir=desc&ratingFilter=0\n",
      "已爬取第5部电影的评论共25条\n",
      "爬虫完毕，共爬取477条用户评论\n"
     ]
    }
   ],
   "source": [
    "# %load movie_review5.py\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "def generate_movie_list_link(i):\n",
    "    movie_list_url = \"https://www.imdb.com/search/title/?title_type=tv_movie&release_date=2019-01-01,2021-01-01&sort=num_votes,desc&start=\"+str((i-1)*50+1)+\"&ref_=adv_nxt\"\n",
    "    return movie_list_url\n",
    "\n",
    "def generate_movie_review_list_link(url):\n",
    "    URL = url\n",
    "    try:\n",
    "        response = requests.get(URL)\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "            soup = BeautifulSoup(html,'lxml')\n",
    "            movies = soup.select('.lister-item-content')\n",
    "            #print(movies)\n",
    "            movie_reviews_url_list = [[0] * 3 for j in range(50)]\n",
    "            i = 0\n",
    "            for movie in movies:\n",
    "                header = movie.select_one('.lister-item-header')\n",
    "                movie_link = header.select_one('a')['href']                     #电影链接\n",
    "                id_pattern = re.compile(r'(?<=tt)\\d+(?=/?)')\n",
    "                movie_id = int(id_pattern.search(movie_link).group())           #imdb电影id\n",
    "                movie_reviews_url = \"https://www.imdb.com/title/tt\"+str(movie_id)+\"/reviews?spoiler=hide&sort=helpfulnessScore&dir=desc&ratingFilter=0\"\n",
    "                movie_name = header.select_one('a').string\n",
    "\n",
    "                movie_reviews_url_list[i] = [movie_name, movie_id, movie_reviews_url]\n",
    "                i += 1\n",
    "                #print(i,movie_name,movie_id,movie_reviews_url)\n",
    "                #time.sleep(1)\n",
    "            return movie_reviews_url_list\n",
    "        else:\n",
    "            print(\"Error when request URL\")\n",
    "    except RequestException:\n",
    "        print(\"Request Failed\")\n",
    "        return None\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def remove_tags(text):\n",
    "    text = str(text)\n",
    "    clean_text = TAG_RE.sub('', text)\n",
    "    clean_text = clean_text.replace(\"[\", \"\")\n",
    "    clean_text = clean_text.replace(\"]\", \"\")\n",
    "    return clean_text\n",
    "\n",
    "#获取imdb电影评论页面所有非spoiler的用户评论\n",
    "def get_imdb_movie_review(url,movieId,movieName):\n",
    "    NETWORK_STATUS = True  # 判断状态变量\n",
    "    URL = url\n",
    "    print(URL)\n",
    "    try:\n",
    "        response = requests.get(URL)\n",
    "        if response.status_code == 200:\n",
    "            original_html = response.text\n",
    "            original_soup = BeautifulSoup(original_html,'lxml')\n",
    "            #需要下载Chromedriver\n",
    "            driver = webdriver.Chrome(\"C:/Program Files/Google/Chrome/Application/chromedriver.exe\")\n",
    "            driver.get(URL)\n",
    "\n",
    "            # 判断是否需要模拟点击load more 按钮\n",
    "            while(1):\n",
    "                temp_response = driver.page_source\n",
    "                temp_html = temp_response\n",
    "                temp_soup = BeautifulSoup(temp_html,'lxml')\n",
    "                load_more = temp_soup.select('.ipl-load-more__button')\n",
    "                #需要模拟点击\n",
    "                if(len(load_more) == 1):\n",
    "                    button_load_more = driver.find_element_by_class_name('ipl-load-more__button')\n",
    "                    button_is_or_not_visible = driver.find_element_by_class_name('ipl-load-more__button').is_displayed()\n",
    "                    if(button_is_or_not_visible is True):       #button按钮不可见时停止点击\n",
    "                        button_load_more.click()\n",
    "                        time.sleep(3)\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            final_response = driver.page_source\n",
    "            html = final_response\n",
    "            soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "            movie_id = movieId\n",
    "            reviews = soup.select('.review-container')\n",
    "            movie_reviews_list = [[0] * 5 for j in range(1500)]\n",
    "            movie_name = movieName\n",
    "\n",
    "            i = 0\n",
    "            for review in reviews:\n",
    "                header = review.select_one('.display-name-date')\n",
    "                user_link = header.select_one('a')['href']\n",
    "                user_id_pattern = re.compile(r'(?<=ur)\\d+(?=/?)')\n",
    "                user_id = int(user_id_pattern.search(user_link).group())    #用户id\n",
    "                review_date = header.select_one('.review-date').string      #用户评论时间\n",
    "\n",
    "                content = review.select_one('.content')\n",
    "                user_review = content.select('.text.show-more__control')     #用户评论\n",
    "                user_review = remove_tags(user_review)\n",
    "\n",
    "                movie_reviews_list[i][0] = user_id\n",
    "                movie_reviews_list[i][1] = review_date\n",
    "                movie_reviews_list[i][2] = user_review\n",
    "                movie_reviews_list[i][3] = movie_id\n",
    "                movie_reviews_list[i][4] = movie_name\n",
    "\n",
    "                i += 1\n",
    "                #print(i,user_id,review_date,user_review,movie_id)\n",
    "                time.sleep(0.01)\n",
    "\n",
    "            driver.close()      #关闭网页\n",
    "            return movie_reviews_list\n",
    "        else:\n",
    "            print(\"Error when request URL\")\n",
    "    except RequestException:\n",
    "        print(\"Request Failed\")\n",
    "        return None\n",
    "    except requests.exceptions.Timeout:\n",
    "        NETWORK_STATUS = False  # 请求超时改变状态\n",
    "        if NETWORK_STATUS == False:\n",
    "            #请求超时\n",
    "            driver.close()  # 关闭网页\n",
    "            print('请求超时，重复请求')\n",
    "            get_imdb_movie_review(URL, movieId, movieName)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    i = 1\n",
    "    countall = 0\n",
    "    count = 0\n",
    "    with open('movie_review_info.csv', 'w', newline=\"\",encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, dialect=(\"excel\"))\n",
    "        csvwriter.writerow([\"userId\", \"reviewDate\", \"userReview\",\"movieId\",\"movieName\"])\n",
    "        #i表示页数，这里只爬取第一页\n",
    "        while (i <= 1):\n",
    "             print(\"第\" + str(i) + \"页电影\")\n",
    "             movie_list_url = generate_movie_list_link(i)\n",
    "             movie_review_url_list = generate_movie_review_list_link(movie_list_url)\n",
    "             j = 0\n",
    "\n",
    "             while (j < 5):\n",
    "                 print(\"第\" + str((i-1) * 50 + j + 1) + \"部电影的评论\")\n",
    "                 l = [[0] * 4 for j in range(1500)]\n",
    "                 l = get_imdb_movie_review(movie_review_url_list[j][2], movie_review_url_list[j][1], movie_review_url_list[j][0])\n",
    "                 k = 0\n",
    "                 if(l is None):\n",
    "                     j += 1\n",
    "                     continue\n",
    "\n",
    "                 while(l[k][0] != 0):\n",
    "                     csvwriter.writerow(l[k])\n",
    "                     k += 1\n",
    "                     count += 1\n",
    "                     countall += 1\n",
    "                 print(\"已爬取第\" + str((i-1) * 50 + j + 1) + \"部电影的评论共\" + str(count) + \"条\")\n",
    "                 j += 1\n",
    "                 count = 0\n",
    "             i += 1\n",
    "\n",
    "    print(\"爬虫完毕，共爬取\"+str(countall)+\"条用户评论\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
